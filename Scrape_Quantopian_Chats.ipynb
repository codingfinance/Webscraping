{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scrape_Quantopian_Chats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLNeAzDQzeRT",
        "colab_type": "text"
      },
      "source": [
        "# Scrape Quantopian's Community Forum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltta_5vKzngH",
        "colab_type": "text"
      },
      "source": [
        "Quantopian is a great place to share ideas. We wanted to learn what Quantopian users are most interested in. So we scraped the discussion forum, to get the data. Once we have the data we can analyze it further. Below is the notebook for all the steps followed in getting the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Y2Mm_V0fwi",
        "colab_type": "text"
      },
      "source": [
        "Import the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDTwyuXLaFkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from urllib.request import urlopen\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAWdi5DnaKts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_url = \"https://www.quantopian.com/posts?page=1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPGswp4IaSPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "req = requests.get(my_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lZqCq18aXKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(req.text, 'lxml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fd6_P2g0kpU",
        "colab_type": "text"
      },
      "source": [
        "Checking just one tag. Since it worked, we will use it to findall items with that tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RswLYaPWabhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84228803-2aa6-434d-8011-1f6c2b831837"
      },
      "source": [
        "soup.find('a', class_=\"user-link\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a class=\"user-link\" href=\"/users/55a2a24cd9946b6c4a0002f3\">Antony Jackson</a>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOhN4nViac4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "b3e55534-c54b-4f78-c5eb-bfd96f0565d4"
      },
      "source": [
        "for i in soup.select(selector='.post-title a'):\n",
        "  print(i['href'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/posts/$10k-third-party-challenge-design-a-factor-for-a-large-us-corporate-pension\n",
            "/posts/conference-opportunity-odsc-east-2020-quantopian-discount\n",
            "/posts/quantopian-strategic-pivot\n",
            "/posts/new-strategy-presenting-the-quality-companies-in-an-uptrend-model-1\n",
            "/posts/alphalens-questions-thread\n",
            "/posts/new-feature-challenge-winner-badge\n",
            "/posts/quantpedia-trading-strategy-series-reversals-in-the-pead\n",
            "/posts/new-video-learn-from-the-experts-ep-1-full-algorithm-creation-with-vedran-rusman\n",
            "/posts/when-to-combine-factors-and-when-not-to\n",
            "/posts/new-tearsheet-challenge-insider-transactions-dataset-5000-dollars-in-prizes\n",
            "/posts/end-of-paper-trading\n",
            "/posts/learning-sdes-in-python\n",
            "/posts/big-news-for-the-community-more-opportunities-to-license-your-algorithms\n",
            "/posts/the-next-quantopian-based-paper-on-uncovering-momentum\n",
            "/posts/forum-update-improved-thread-load-times\n",
            "/posts/upgrading-to-python-3\n",
            "/posts/futures-data-now-available-in-research\n",
            "/posts/general-update-on-quantopian-oss\n",
            "/posts/how-to-get-an-allocation-in-2019\n",
            "/posts/new-book-on-quantopian-slash-zipline-backtesting-and-modeling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHtqqDwr0u9v",
        "colab_type": "text"
      },
      "source": [
        "Getting the total views for each post. We can use this analyze the most popular posts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reY0Htmue2WJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "4a677fe0-9b22-4126-8974-34c4e4c88a20"
      },
      "source": [
        "for i in soup.select(selector='.views span'):\n",
        "  print(i.text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9k\n",
            "Views\n",
            "71\n",
            "Views\n",
            "331\n",
            "Views\n",
            "19.5k\n",
            "Views\n",
            "13.6k\n",
            "Views\n",
            "196\n",
            "Views\n",
            "19.9k\n",
            "Views\n",
            "1.3k\n",
            "Views\n",
            "1.2k\n",
            "Views\n",
            "10.4k\n",
            "Views\n",
            "5.7k\n",
            "Views\n",
            "7.5k\n",
            "Views\n",
            "4.4k\n",
            "Views\n",
            "3.5k\n",
            "Views\n",
            "180\n",
            "Views\n",
            "3.4k\n",
            "Views\n",
            "24.6k\n",
            "Views\n",
            "321\n",
            "Views\n",
            "7.8k\n",
            "Views\n",
            "16.7k\n",
            "Views\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3JxcenB04W0",
        "colab_type": "text"
      },
      "source": [
        "Getting the articles replies. This can indicate which articles produced the most discussion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySUFAkj1fMyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "2e9004f9-a640-46b9-831c-b1b92d664f8b"
      },
      "source": [
        "for i in soup.select(selector='.replies span'):\n",
        "  print(i.text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "259\n",
            "Replies\n",
            "0\n",
            "Replies\n",
            "1\n",
            "Reply\n",
            "258\n",
            "Replies\n",
            "126\n",
            "Replies\n",
            "0\n",
            "Replies\n",
            "38\n",
            "Replies\n",
            "16\n",
            "Replies\n",
            "11\n",
            "Replies\n",
            "210\n",
            "Replies\n",
            "54\n",
            "Replies\n",
            "5\n",
            "Replies\n",
            "37\n",
            "Replies\n",
            "7\n",
            "Replies\n",
            "1\n",
            "Reply\n",
            "18\n",
            "Replies\n",
            "57\n",
            "Replies\n",
            "1\n",
            "Reply\n",
            "43\n",
            "Replies\n",
            "123\n",
            "Replies\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IowVjqvg1DlB",
        "colab_type": "text"
      },
      "source": [
        "This is the main funtion that scrapes all the data. We can provide the page_num as an argument and it will get the data for that page.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUBjOs5IcxXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_quantopian(page_num):\n",
        "\n",
        "  my_url = \"https://www.quantopian.com/posts?page=\"+str(page_num)\n",
        "\n",
        "  req = requests.get(my_url)\n",
        "\n",
        "  soup = BeautifulSoup(req.text, 'lxml')\n",
        "\n",
        "\n",
        "  links = []\n",
        "  title = []\n",
        "  author = []\n",
        "  views = []\n",
        "  replies = []\n",
        "\n",
        "  for i in soup.select(selector='.post-title a'):\n",
        "    links.append(i['href'])\n",
        "  \n",
        "  for i in soup.select(selector='.post-title a'):\n",
        "    title.append(i.text)\n",
        "  for i in soup.select(selector='.views span'):\n",
        "    views.append(i.text)\n",
        "  for i in soup.select(selector='.replies span'):\n",
        "    replies.append(i.text)\n",
        "\n",
        "  for i in soup.select(selector='.user-link'):\n",
        "    author.append(i.text)\n",
        "\n",
        "  return title, author, views, replies, links\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0G75Y_b1ROk",
        "colab_type": "text"
      },
      "source": [
        "Testing the function on page 33."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5pctNbvdvPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t, a, v, r, l = get_quantopian(page_num=33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N5SjNNQ1YD9",
        "colab_type": "text"
      },
      "source": [
        "The Replies and Views data comes with extra string that we dont need. So we are removing it from our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE2m5C38d56I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the str(Replies | Reply) from our data\n",
        "\n",
        "f1 = np.unique(r)[-1]\n",
        "f2 = np.unique(r)[-2]\n",
        "r = list(filter(lambda x: x != f1, r))\n",
        "r = list(filter(lambda x: x != f2, r))\n",
        "\n",
        "# Remove word Views from v\n",
        "f3 = np.unique(v)[-1]\n",
        "v = list(filter(lambda x: x != f3, v))\n",
        "\n",
        "# Storing the data in a data frame\n",
        "quantopian_df = pd.DataFrame({'title':t,\n",
        "              'author':a,\n",
        "              'views':v,\n",
        "              'replies':r,\n",
        "              'links':l})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tDlHZU_1nyS",
        "colab_type": "text"
      },
      "source": [
        "We can see the data has been saved in the below Data Frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UBOx7SHd8Og",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "6e8b68f5-4396-42e3-8d76-ccee416923ce"
      },
      "source": [
        "# Hiding Author's name\n",
        "# We dont want to display it on github, where this\n",
        "# Notebook will be posted.\n",
        "\n",
        "quantopian_df.drop(columns='author')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>replies</th>\n",
              "      <th>links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Happy 3rd Birthday to Our Community!</td>\n",
              "      <td>663</td>\n",
              "      <td>4</td>\n",
              "      <td>/posts/happy-3rd-birthday-to-our-community</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Curriculum of study/books</td>\n",
              "      <td>14.3k</td>\n",
              "      <td>18</td>\n",
              "      <td>/posts/curriculum-of-study-slash-books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Warren Buffett Market Crash Predictions: The C...</td>\n",
              "      <td>1k</td>\n",
              "      <td>1</td>\n",
              "      <td>/posts/warren-buffett-market-crash-predictions...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Quantopian Lecture Series: Notebooks, Back...</td>\n",
              "      <td>3k</td>\n",
              "      <td>3</td>\n",
              "      <td>/posts/the-quantopian-lecture-series-notebooks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UPDATE: Front Running S&amp;P 500 Index Funds</td>\n",
              "      <td>2.7k</td>\n",
              "      <td>0</td>\n",
              "      <td>/posts/update-front-running-s-and-p-500-index-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Brent/WTI Spread Fetcher Example</td>\n",
              "      <td>17.7k</td>\n",
              "      <td>14</td>\n",
              "      <td>/posts/brent-slash-wti-spread-fetcher-example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Research Cheat Sheet: easily move between the ...</td>\n",
              "      <td>4.9k</td>\n",
              "      <td>5</td>\n",
              "      <td>/posts/research-cheat-sheet-easily-move-betwee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Seeking Feedback on Trading based on Sentiment...</td>\n",
              "      <td>4.1k</td>\n",
              "      <td>13</td>\n",
              "      <td>/posts/seeking-feedback-on-trading-based-on-se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Mebane Faber Relative Strength Strategy with M...</td>\n",
              "      <td>41.9k</td>\n",
              "      <td>23</td>\n",
              "      <td>/posts/mebane-faber-relative-strength-strategy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Automated Leverage System</td>\n",
              "      <td>1.2k</td>\n",
              "      <td>1</td>\n",
              "      <td>/posts/automated-leverage-system</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Avoiding the Twitter Leak with Accern Sentimen...</td>\n",
              "      <td>1.1k</td>\n",
              "      <td>3</td>\n",
              "      <td>/posts/avoiding-the-twitter-leak-with-accern-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Backtest a unique news and blog dataset from A...</td>\n",
              "      <td>662</td>\n",
              "      <td>0</td>\n",
              "      <td>/posts/backtest-a-unique-news-and-blog-dataset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>discuss the sample algorithm</td>\n",
              "      <td>68.2k</td>\n",
              "      <td>23</td>\n",
              "      <td>/posts/discuss-the-sample-algorithm-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Run Summary</td>\n",
              "      <td>4.2k</td>\n",
              "      <td>16</td>\n",
              "      <td>/posts/run-summary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ranking and Trading on \"Days to Cover\"</td>\n",
              "      <td>36.2k</td>\n",
              "      <td>5</td>\n",
              "      <td>/posts/ranking-and-trading-on-days-to-cover</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Paper Trading With Interactive Brokers - Open ...</td>\n",
              "      <td>40.7k</td>\n",
              "      <td>97</td>\n",
              "      <td>/posts/paper-trading-with-interactive-brokers-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  ...                                              links\n",
              "0                Happy 3rd Birthday to Our Community!  ...         /posts/happy-3rd-birthday-to-our-community\n",
              "1                           Curriculum of study/books  ...             /posts/curriculum-of-study-slash-books\n",
              "2   Warren Buffett Market Crash Predictions: The C...  ...  /posts/warren-buffett-market-crash-predictions...\n",
              "3   The Quantopian Lecture Series: Notebooks, Back...  ...  /posts/the-quantopian-lecture-series-notebooks...\n",
              "4           UPDATE: Front Running S&P 500 Index Funds  ...  /posts/update-front-running-s-and-p-500-index-...\n",
              "5                    Brent/WTI Spread Fetcher Example  ...      /posts/brent-slash-wti-spread-fetcher-example\n",
              "6   Research Cheat Sheet: easily move between the ...  ...  /posts/research-cheat-sheet-easily-move-betwee...\n",
              "7   Seeking Feedback on Trading based on Sentiment...  ...  /posts/seeking-feedback-on-trading-based-on-se...\n",
              "8   Mebane Faber Relative Strength Strategy with M...  ...  /posts/mebane-faber-relative-strength-strategy...\n",
              "9                           Automated Leverage System  ...                   /posts/automated-leverage-system\n",
              "10  Avoiding the Twitter Leak with Accern Sentimen...  ...  /posts/avoiding-the-twitter-leak-with-accern-s...\n",
              "11  Backtest a unique news and blog dataset from A...  ...  /posts/backtest-a-unique-news-and-blog-dataset...\n",
              "12                       discuss the sample algorithm  ...              /posts/discuss-the-sample-algorithm-1\n",
              "13                                        Run Summary  ...                                 /posts/run-summary\n",
              "14             Ranking and Trading on \"Days to Cover\"  ...        /posts/ranking-and-trading-on-days-to-cover\n",
              "15  Paper Trading With Interactive Brokers - Open ...  ...  /posts/paper-trading-with-interactive-brokers-...\n",
              "\n",
              "[16 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSAgos-Gd9nY",
        "colab_type": "text"
      },
      "source": [
        "Now we can do the same for all 33 pages. We will write a for loop and get all the data. We are going to put the system to sleep for random intervals (between 1 to 4 seconds) for each loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_JO3kmmQif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "efde6491-22b2-4fd0-da9e-6da8fffc4070"
      },
      "source": [
        "t1 = []\n",
        "a1 = []\n",
        "v1 = []\n",
        "r1 = []\n",
        "l1 = []\n",
        "\n",
        "for i in range(1,34):\n",
        "\n",
        "  import time\n",
        "\n",
        "  sleep_t = np.random.randint(low=1,high=4,size=1)\n",
        "  time.sleep(sleep_t)\n",
        "\n",
        "  t, a, v, r, l = get_quantopian(i)\n",
        "\n",
        "  t1.append(t)\n",
        "  a1.append(a)\n",
        "  v1.append(v)\n",
        "  r1.append(r)\n",
        "  l1.append(l)\n",
        "  print(f\"Finished getting data for page {i}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished getting data for page 1\n",
            "Finished getting data for page 2\n",
            "Finished getting data for page 3\n",
            "Finished getting data for page 4\n",
            "Finished getting data for page 5\n",
            "Finished getting data for page 6\n",
            "Finished getting data for page 7\n",
            "Finished getting data for page 8\n",
            "Finished getting data for page 9\n",
            "Finished getting data for page 10\n",
            "Finished getting data for page 11\n",
            "Finished getting data for page 12\n",
            "Finished getting data for page 13\n",
            "Finished getting data for page 14\n",
            "Finished getting data for page 15\n",
            "Finished getting data for page 16\n",
            "Finished getting data for page 17\n",
            "Finished getting data for page 18\n",
            "Finished getting data for page 19\n",
            "Finished getting data for page 20\n",
            "Finished getting data for page 21\n",
            "Finished getting data for page 22\n",
            "Finished getting data for page 23\n",
            "Finished getting data for page 24\n",
            "Finished getting data for page 25\n",
            "Finished getting data for page 26\n",
            "Finished getting data for page 27\n",
            "Finished getting data for page 28\n",
            "Finished getting data for page 29\n",
            "Finished getting data for page 30\n",
            "Finished getting data for page 31\n",
            "Finished getting data for page 32\n",
            "Finished getting data for page 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qVrSaQP2TI4",
        "colab_type": "text"
      },
      "source": [
        "Checking the length of all the lists. These are all the same. But they are nested lists. We will flatten them using the below function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUJbFClFmiKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "acb98b9c-b5e4-424a-cf11-e0c85ecc9bca"
      },
      "source": [
        "len(t1), len(a1), len(l1), len(v1), len(r1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33, 33, 33, 33, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXVmf7t7qbZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(your_list):\n",
        "\n",
        "  flat_list = []\n",
        "  \n",
        "  for sublist in your_list:\n",
        "    for item in sublist:\n",
        "      flat_list.append(item)\n",
        "  return flat_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjEG4F2HrjKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_a1 = flatten(a1)\n",
        "flat_t1 = flatten(t1)\n",
        "flat_l1 = flatten(l1)\n",
        "flat_v1 = flatten(v1)\n",
        "flat_r1 = flatten(r1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYOksanp2fKo",
        "colab_type": "text"
      },
      "source": [
        "Now all our lists are flatten. We need to remove the extra strings from the replies and views data, just as we did above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WUbAymMro3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dda0872d-c25f-4a15-d577-6e5fb716f5c2"
      },
      "source": [
        "len(flat_a1), len(flat_t1), len(flat_l1), len(flat_v1), len(flat_r1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(656, 656, 656, 1312, 1312)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZk29DqT3zN0",
        "colab_type": "text"
      },
      "source": [
        "As we can see the list are of unequal length. We need to remove the extra strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVI5QYixr8k9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "faeaea21-5468-4b09-e584-7fc77a38f697"
      },
      "source": [
        "# Remove the str(Replies | Reply)\n",
        "\n",
        "f1 = np.unique(flat_r1)[-1]\n",
        "f2 = np.unique(flat_r1)[-2]\n",
        "f1,f2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Reply', 'Replies')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EldkwK1msKwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the replies keyword"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJnA5Z0NsN13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_r1 = list(filter(lambda x: x!=f2,flat_r1))\n",
        "flat_r1 = list(filter(lambda x: x!=f1,flat_r1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjTn6fErqn6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove word Views from v\n",
        "f3 = np.unique(flat_v1)[-1]\n",
        "flat_v1 = list(filter(lambda x: x != f3, flat_v1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY4FRjCDsuW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c17b6e1e-112c-4257-82b2-cf32737fbb40"
      },
      "source": [
        "len(flat_a1), len(flat_t1), len(flat_l1), len(flat_v1), len(flat_r1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(656, 656, 656, 656, 656)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgGF3DP_svo4",
        "colab_type": "text"
      },
      "source": [
        "Now our lists are the same length. So lets make our DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKnoPXJmszNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantopian_df_large = pd.DataFrame({'title':flat_t1,\n",
        "              'author':flat_a1,\n",
        "              'views':flat_v1,\n",
        "              'replies':flat_r1,\n",
        "              'links':flat_l1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djNlD6IKp_Nn",
        "colab_type": "text"
      },
      "source": [
        "Convert views column to float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8g3j0_JtDg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantopian_df_large['views_float'] = (quantopian_df_large['views'].replace(r'[kK]+$','',regex=True).astype(float) * \\\n",
        " quantopian_df_large['views'].str.extract(r'[\\d\\.]+([kK]+)', expand = False).fillna(1).replace(['k'], [1000]).astype(int))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xzk1u6fvB2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "caf7a231-4dc0-4bb0-cdfd-3c4a546b7840"
      },
      "source": [
        "quantopian_df_large.drop(columns='author')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>replies</th>\n",
              "      <th>links</th>\n",
              "      <th>views_float</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>$10K Third-Party Challenge: Design a Factor fo...</td>\n",
              "      <td>9k</td>\n",
              "      <td>259</td>\n",
              "      <td>/posts/$10k-third-party-challenge-design-a-fac...</td>\n",
              "      <td>9000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Conference Opportunity: ODSC East 2020 Quantop...</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>/posts/conference-opportunity-odsc-east-2020-q...</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Quantopian Strategic Pivot</td>\n",
              "      <td>331</td>\n",
              "      <td>1</td>\n",
              "      <td>/posts/quantopian-strategic-pivot</td>\n",
              "      <td>331.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>New Strategy - Presenting the “Quality Compani...</td>\n",
              "      <td>19.5k</td>\n",
              "      <td>258</td>\n",
              "      <td>/posts/new-strategy-presenting-the-quality-com...</td>\n",
              "      <td>19500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alphalens Questions Thread</td>\n",
              "      <td>13.6k</td>\n",
              "      <td>126</td>\n",
              "      <td>/posts/alphalens-questions-thread</td>\n",
              "      <td>13600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>Backtest a unique news and blog dataset from A...</td>\n",
              "      <td>662</td>\n",
              "      <td>0</td>\n",
              "      <td>/posts/backtest-a-unique-news-and-blog-dataset...</td>\n",
              "      <td>662.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>discuss the sample algorithm</td>\n",
              "      <td>68.2k</td>\n",
              "      <td>23</td>\n",
              "      <td>/posts/discuss-the-sample-algorithm-1</td>\n",
              "      <td>68200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>Run Summary</td>\n",
              "      <td>4.2k</td>\n",
              "      <td>16</td>\n",
              "      <td>/posts/run-summary</td>\n",
              "      <td>4200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>Ranking and Trading on \"Days to Cover\"</td>\n",
              "      <td>36.2k</td>\n",
              "      <td>5</td>\n",
              "      <td>/posts/ranking-and-trading-on-days-to-cover</td>\n",
              "      <td>36200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>Paper Trading With Interactive Brokers - Open ...</td>\n",
              "      <td>40.7k</td>\n",
              "      <td>97</td>\n",
              "      <td>/posts/paper-trading-with-interactive-brokers-...</td>\n",
              "      <td>40700.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>656 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title  ... views_float\n",
              "0    $10K Third-Party Challenge: Design a Factor fo...  ...      9000.0\n",
              "1    Conference Opportunity: ODSC East 2020 Quantop...  ...        71.0\n",
              "2                           Quantopian Strategic Pivot  ...       331.0\n",
              "3    New Strategy - Presenting the “Quality Compani...  ...     19500.0\n",
              "4                           Alphalens Questions Thread  ...     13600.0\n",
              "..                                                 ...  ...         ...\n",
              "651  Backtest a unique news and blog dataset from A...  ...       662.0\n",
              "652                       discuss the sample algorithm  ...     68200.0\n",
              "653                                        Run Summary  ...      4200.0\n",
              "654             Ranking and Trading on \"Days to Cover\"  ...     36200.0\n",
              "655  Paper Trading With Interactive Brokers - Open ...  ...     40700.0\n",
              "\n",
              "[656 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9o-KfEuxmPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}